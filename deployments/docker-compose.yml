version: '3'
services:
# Postgres database for persisting users and urls
  db:
    image: postgres
    hostname: db
    container_name: db
    restart: always
    environment:
      POSTGRES_PASSWORD: secret
      POSTGRES_USER: yekta
      POSTGRES_DB: test
    networks:
      intranet:
        ipv4_address: 10.5.0.10
# clicktweak core service
  core:
    image: reg.alipanah.me/core
    hostname: core
    container_name: core
    restart: always
    ports:
      - 8080:80
    volumes:
      - ../configs/core.toml:/etc/config.toml
    networks:
      intranet:
        ipv4_address: 10.5.0.20
    depends_on:
      - db
# clicktweak service for redirection and access log generation
  dispatcher:
    image: reg.alipanah.me/dispatcher
    hostname: dispatcher
    container_name: dispatcher
    restart: always
    ports:
      - 8081:80
    volumes:
      - ../configs/dispatcher.toml:/etc/config.toml
    networks:
      intranet:
        ipv4_address: 10.5.0.30
    depends_on:
      - forwarder
      - db
# clicktweak service for consumption of kafka events and pushing to clickhouse
  consumer:
    image: reg.alipanah.me/consumer
    hostname: consumer
    container_name: consumer
    restart: always
    volumes:
      - ../configs/consumer.toml:/etc/config.toml
    networks:
      intranet:
        ipv4_address: 10.5.0.80
    depends_on:
      - forwarder
      - clickhouse
      - kafka
# clicktweak service responsible for report generation
  analyzer:
    image: reg.alipanah.me/analyzer
    hostname: analyzer
    container_name: analyzer
    restart: always
    ports:
      - 8082:80
    volumes:
      - ../configs/analyzer.toml:/etc/config.toml
    networks:
      intranet:
        ipv4_address: 10.5.0.90
    depends_on:
      - db
      - clickhouse
      - consumer
# fluent-bit log forwarder which forwards access log to kafka
  forwarder:
    image: fluent/fluent-bit:1.3
    hostname: forwarder
    container_name: forwarder
    restart: always
    logging:
      driver: json-file
      options:
        max-size: 10m
        max-file: "1"
    volumes:
      - ../configs/forwarder.conf:/fluent-bit/etc/fluent-bit.conf
    networks:
      intranet:
        ipv4_address: 10.5.0.40
    depends_on:
      - kafka
# zoo kafka manager
  zoo:
    image: zookeeper:3.4.9
    hostname: zoo
    container_name: zoo
    ports:
      - "2181:2181"
    environment:
      ZOO_MY_ID: 1
      ZOO_PORT: 2181
      ZOO_SERVERS: server.1=zoo:2888:3888
    volumes:
      - ./zk-single-kafka-single/zoo1/data:/data
      - ./zk-single-kafka-single/zoo1/datalog:/datalog
    networks:
      intranet:
        ipv4_address: 10.5.0.50
# kafka instance
  kafka:
    image: confluentinc/cp-kafka:5.5.0
    hostname: kafka
    container_name: kafka
    ports:
      - "9092:9092"
    environment:
      KAFKA_ADVERTISED_LISTENERS: LISTENER_DOCKER_INTERNAL://kafka:19092,LISTENER_DOCKER_EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: LISTENER_DOCKER_INTERNAL:PLAINTEXT,LISTENER_DOCKER_EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: LISTENER_DOCKER_INTERNAL
      KAFKA_ZOOKEEPER_CONNECT: "zoo:2181"
      KAFKA_BROKER_ID: 1
      KAFKA_LOG4J_LOGGERS: "kafka.controller=WARN,kafka.producer.async.DefaultEventHandler=WARN,state.change.logger=WARN"
      KAFKA_LOG4J_ROOT_LOGLEVEL: "WARN"
      KAFKA_TOOLS_LOG4J_LOGLEVEL: "ERROR"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    volumes:
      - ./zk-single-kafka-single/kafka1/data:/var/lib/kafka/data
    links:
      - zoo
    networks:
      intranet:
        ipv4_address: 10.5.0.60
    depends_on:
      - zoo
# clickhouse for log aggregation
  clickhouse:
    image: yandex/clickhouse-server
    hostname: clickhouse
    container_name: clickhouse
    ports:
      - 8123:8123
      - 9000:9000
      - 9009:9009
    networks:
      intranet:
        ipv4_address: 10.5.0.70

# bridge network among services
networks:
  intranet:
    driver: bridge
    ipam:
      config:
        - subnet: 10.5.0.0/16
